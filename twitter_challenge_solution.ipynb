{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rziXcUSBskS3"
   },
   "outputs": [],
   "source": [
    "    #from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Developer Account\n",
    "In order to use Twitter’s API, we have to create a developer account on the Twitter apps site.\n",
    " * Log in or make a Twitter account at https://apps.twitter.com/.\n",
    " * Create a new app (button on the top right)\n",
    " \n",
    "<img src=https://miro.medium.com/max/1400/0*Dq78m3JKoSqZY5SS.png style=\"width: 200px;\">\n",
    "\n",
    "Fill in the app creation page with a unique name, a website name (use a placeholder website if you don’t have one), and a project description. Accept the terms and conditions and proceed to the next page.\n",
    "\n",
    "Example Purpose Statement\n",
    ">>> At the moment I am taking a data science course from 10academy.org initiative. As part of the training, I am working on a project that involves fetching twitter data on a number of African countries related to COVID-19 vaccination topics. To fetch twitter data and make exploratory data analysis, I need to be able to access twitter through its API. This is the main reason why I want to create a developer account. I hope you will look my application favoroubly. \n",
    "I have read the terms of use, and I fully agree with it. Twitter is a great source of data to study social, economical, and political issus, and I hope to use my data science skills to provide insights on this issues in the future as well.\n",
    "\n",
    "\n",
    "Once your project has been created, click on the “Keys and Access Tokens” tab. You should now be able to see your consumer secret and consumer key.\n",
    "\n",
    "<img src=https://miro.medium.com/max/1400/0*YU1pFqTw6Dn-ZmOd.png style=\"width: 200px;\">\n",
    "\n",
    "You’ll also need a pair of access tokens. Scroll down and request those tokens. The page should refresh, and you should now have an access token and access token secret.\n",
    "\n",
    "<img src=https://miro.medium.com/max/1400/0*_gnOgA0aaAqPgDJG.png style=\"width: 200px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UI2fIQFxrNLB",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from tqdm.notebook import nbtqdm\n",
    "#from tqdm import tqdm\n",
    "from datetime import datetime, date, time, timedelta\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "\n",
    "# to view all columns\n",
    "pd.set_option(\"display.max.columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3pf5Xapqrq0M"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/alex/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Import the necessary methods from tweepy library  \n",
    "\n",
    "#install tweepy if you don't have it\n",
    "#!pip install tweepy\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "\n",
    "#sentiment analysis package\n",
    "#!pip install textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "#general text pre-processor\n",
    "#!pip install nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "\n",
    "#tweet pre-processor \n",
    "#!pip install tweet-preprocessor\n",
    "import preprocessor as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full(x):\n",
    "  '''\n",
    "  This is to print nicely DataFrame wide tables\n",
    "  '''\n",
    "  pd.set_option('display.max_rows', len(x))\n",
    "  pd.set_option('display.max_columns', None)\n",
    "  pd.set_option('display.width', 2000)\n",
    "  pd.set_option('display.float_format', '{:20,.2f}'.format)\n",
    "  pd.set_option('display.max_colwidth', -1)\n",
    "  print(x)\n",
    "  pd.reset_option('display.max_rows')\n",
    "  pd.reset_option('display.max_columns')\n",
    "  pd.reset_option('display.width')\n",
    "  pd.reset_option('display.float_format')\n",
    "  pd.reset_option('display.max_colwidth')\n",
    "    \n",
    "    \n",
    "def refresh_status_bar(text, verbose=1):\n",
    "    if verbose:\n",
    "        print('{}'.format(text),file=sys.stderr, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting code\n",
    "Below we define some starting codes (python classes and function) to illustrate and assist on how to fetch data from twitter and analyse them. \n",
    "\n",
    "### **Your task is**\n",
    "1. Go through the code and understand it. Know what each function does\n",
    "2. If you find error, fix it. Ask for help in the slack channel if you find serious mistake\n",
    "3. Extend the code such that it will be useful for topics you choose to analyse\n",
    "4. Make nice plots and share your finding (e.g.  insight on the main covid19 twitter converstions about your country)\n",
    "5. Submit what ever you managed to do by Wednesday morning. But you should keep using what you build to write blogs, share on facebook, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a basic listener that writes received tweets to file.\n",
    "class StdOutListener(tweepy.Stream):\n",
    "\n",
    "    def __init__(self,fhandle, stop_at = 1000):\n",
    "        self.tweet_counter = 0\n",
    "        self.stop_at = stop_at\n",
    "        self.fhandle = fhandle\n",
    "         \n",
    "        \n",
    "    def on_data(self, data):\n",
    "        self.fhandle.write(data)\n",
    "        \n",
    "        #stop if enough tweets are obtained\n",
    "        self.tweet_counter += 1   \n",
    "        if self.tweet_counter < self.stop_at:        \n",
    "            return True\n",
    "        else:\n",
    "            print('Max number of tweets reached: #tweets = ' + str(self.tweet_counter))\n",
    "            return False\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print (status)\n",
    "\n",
    "def stream_tweet_data(filename='data/tweets.json',\n",
    "                      keywords=['COVID19KE'],\n",
    "                      is_async=False):\n",
    "    # tweet topics to use as a filter. The tweets downloaded\n",
    "    # will have one of the topics in their text or hashtag \n",
    "\n",
    "    print('saving data to file: ',filename)\n",
    "\n",
    "    #print the tweet topics \n",
    "    print('Tweet Keywords are: ',keywords)\n",
    "    print('For testing case, please interupt the downloading process \\\n",
    "            using ctrl+x after about 5 mins ')\n",
    "    print('To keep streaming in the background, pass is_async=True')\n",
    "\n",
    "    #Variables that contains the user credentials to access Twitter API \n",
    "    consumer_key = os.environ.get('TWITTER_API_KEY')\n",
    "    consumer_secret = os.environ.get('TWITTER_API_SECRET')\n",
    "    access_token = os.environ.get('TWITTER_ACCESS_TOKEN')\n",
    "    access_token_secret = os.environ.get('TWITTER_ACCESS_TOKEN_SECRET')\n",
    "    \n",
    "\n",
    "    #open file \n",
    "    fhandle=open(filename,'w')\n",
    "\n",
    "    #This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "    l = StdOutListener(fhandle)\n",
    "    auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "    stream = Stream(auth, l)\n",
    "\n",
    "    #This line filter Twitter Streams to capture data by the keywords: first argument to this code\n",
    "    stream.filter(track=keywords,is_async=is_async)\n",
    "\n",
    "    return None\n",
    "\n",
    "def read_tweet_json(tweets_file,verbose=1, func=lambda x:x, nmax=0):\n",
    "    '''\n",
    "    Read a twitter raw json dumped file into a list.\n",
    "    It attempts two methods:\n",
    "        1) read line by line and parse each line using json.loads\n",
    "        2) assuming there was no \\n used, load everything, replace \n",
    "    '''\n",
    "    #\n",
    "    \n",
    "    try:     \n",
    "        print('trying method 1')\n",
    "        tweets_data = []\n",
    "        iline = 0\n",
    "        num_failed=0\n",
    "        \n",
    "        for line in open(tweets_file, \"r\"):\n",
    "            try:\n",
    "                tweet = func(json.loads(line.strip()))\n",
    "                tweets_data.append(tweet)\n",
    "            except:\n",
    "                print(f'failed to process line={iline}')\n",
    "                num_failed += 1\n",
    "                #print(line)\n",
    "            if nmax>0 and iline>nmax:\n",
    "                break\n",
    "                \n",
    "            iline += 1\n",
    "             \n",
    "    except:\n",
    "        iline = 0\n",
    "        num_failed=0\n",
    "        \n",
    "        print('trying method 2')\n",
    "        with open(tweets_file) as f:\n",
    "            tweets_data = json.loads(\"[\" + f.read().replace(\"}\\n{\", \"},\\n{\") + '{}'+ \"]\")  \n",
    "            \n",
    "        tweets_data = [func(status) for status in tweets_data]\n",
    "    #    \n",
    "    if verbose>0:\n",
    "        print(f'#tweets from {tweets_file}: {len(tweets_data)}')\n",
    "        print(f'number of lines failed to read: {num_failed}' )\n",
    "        \n",
    "    return tweets_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class tweetsearch():\n",
    "    '''\n",
    "    This is a basic class to search and download twitter data.\n",
    "    You can build up on it to extend the functionalities for more \n",
    "    sophisticated analysis\n",
    "    '''\n",
    "    def __init__(self, cols=None,auth=None, **kwargs):\n",
    "        #\n",
    "        \n",
    "        self.verbose = kwargs.get('verbose',1)\n",
    "        \n",
    "        #\n",
    "        if not cols is None:\n",
    "            self.cols = cols\n",
    "        else:\n",
    "            self.cols = ['id', 'created_at', 'source', 'original_text','clean_text', \n",
    "                    'sentiment','polarity','subjectivity', 'lang',\n",
    "                    'favorite_count', 'retweet_count', 'original_author',   \n",
    "                    'possibly_sensitive', 'hashtags',\n",
    "                    'user_mentions', 'place', 'place_coord_boundaries']\n",
    "            \n",
    "        if auth is None:\n",
    "            \n",
    "            #Variables that contains the user credentials to access Twitter API \n",
    "            consumer_key = os.environ.get('TWITTER_API_KEY')\n",
    "            consumer_secret = os.environ.get('TWITTER_API_SECRET')\n",
    "            access_token = os.environ.get('TWITTER_ACCESS_TOKEN')\n",
    "            access_token_secret = os.environ.get('TWITTER_ACCESS_TOKEN_SECRET')\n",
    "            \n",
    "\n",
    "\n",
    "            #This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "            auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "            auth.set_access_token(access_token, access_token_secret)\n",
    "            \n",
    "\n",
    "        #            \n",
    "        self.auth = auth\n",
    "        self.api = tweepy.API(auth,wait_on_rate_limit=True) \n",
    "        self.filtered_tweet = ''\n",
    "            \n",
    "    def limit_status(self):\n",
    "        return self.api.rate_limit_status()\n",
    "\n",
    "    def clean_tweets(self, twitter_text):\n",
    "\n",
    "         #HappyEmoticons\n",
    "        emoticons_happy = set([\n",
    "            ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "            ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "            '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "            'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "            '<3'\n",
    "            ])\n",
    "\n",
    "        # Sad Emoticons\n",
    "        emoticons_sad = set([\n",
    "            ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "            ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "            ':c', ':{', '>:\\\\', ';('\n",
    "            ])\n",
    "\n",
    "        #Emoji patterns\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                 u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                 u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                 u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                 u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                 u\"\\U00002702-\\U000027B0\"\n",
    "                 u\"\\U000024C2-\\U0001F251\"\n",
    "                 \"]+\", flags=re.UNICODE)\n",
    "\n",
    "        #combine sad and happy emoticons\n",
    "        emoticons = emoticons_happy.union(emoticons_sad)\n",
    "        \n",
    "        #use pre processor\n",
    "        tweet = p.clean(twitter_text)\n",
    "        \n",
    "        #after tweepy preprocessing the colon symbol left remain after      \n",
    "        #removing mentions\n",
    "        tweet = re.sub(r':', '', tweet)\n",
    "        tweet = re.sub(r'‚Ä¶', '', tweet)\n",
    "\n",
    "        #replace consecutive non-ASCII characters with a space\n",
    "        tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
    "\n",
    "        #remove emojis from tweet\n",
    "        tweet = emoji_pattern.sub(r'', tweet)\n",
    "\n",
    "        return tweet\n",
    "    \n",
    "\n",
    "        \n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        try:\n",
    "            word_tokens = nltk.word_tokenize(tweet)\n",
    "        except:\n",
    "            #print(f'word_tokenize failed for cleaned tweet: {tweet}')\n",
    "            pass\n",
    "        \n",
    "        #filter using NLTK library append it to a string\n",
    "        filtered_tweet = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "        #looping through conditions\n",
    "        filtered_tweet = []    \n",
    "        for w in word_tokens:\n",
    "        #check tokens against stop words , emoticons and punctuations\n",
    "            if w not in stop_words and w not in emoticons and w not in string.punctuation:\n",
    "                filtered_tweet.append(w)\n",
    "\n",
    "        return ' '.join(filtered_tweet) \n",
    "    \n",
    "\n",
    "    def get_user_data(self,target):\n",
    "    \n",
    "        #test if screen name exists \n",
    "        try:\n",
    "            #print(\"Getting data for \" + target)\n",
    "            item = self.api.get_user(target)  \n",
    "            \n",
    "            #derived params\n",
    "            tweets = item.statuses_count\n",
    "            account_created_date = item.created_at\n",
    "            delta = datetime.utcnow() - account_created_date\n",
    "            account_age_days = delta.days\n",
    "            average_tweet_per_day = float(tweets)/float(account_age_days)\n",
    "            \n",
    "            item = item._json\n",
    "            item['account_age_days'] = account_age_days\n",
    "            item['average_tweet_per_day'] = average_tweet_per_day\n",
    "            \n",
    "        except tweepy.TweepError as e:\n",
    "            print()\n",
    "            print(f\"ERROR CODE: {e.args[0][0]['code']}: {e.args[0][0]['message']}\")\n",
    "            print(f'issue with reading screen_name = {target}')\n",
    "            item = None\n",
    "            \n",
    "        return item\n",
    "            \n",
    "            \n",
    "    def get_screen_names(self,users, **kwargs):\n",
    "        \n",
    "        csv = kwargs.get('csv',False)\n",
    "        col = kwargs.get('col','twitter_handle')\n",
    "        nusers = kwargs.get('nusers',0)\n",
    "        \n",
    "        if csv:\n",
    "            try:\n",
    "                print(users)\n",
    "                df = pd.read_csv(users)\n",
    "                print(df.head())\n",
    "                users = df[col].to_list()\n",
    "            except:\n",
    "                print(f'failing to get users name from column={col} of file {users}' )\n",
    "                raise\n",
    "        else:\n",
    "            if not isinstance(users, (list, tuple, set)):\n",
    "                print('Provided users input is not list or tuple. The type(users)',type(users))\n",
    "            \n",
    "        #allow to get only few numbers\n",
    "        users_to_get = users\n",
    "        if nusers>0 and nusers<=len(users):\n",
    "            users_to_get = users[0:nusers]\n",
    "            \n",
    "        return users_to_get\n",
    "    \n",
    "    def get_users_info(self,users, \n",
    "                      csv=True, \n",
    "                      col='Name',                        \n",
    "                      nusers=0, \n",
    "                      fname=None,\n",
    "                      **kwargs):\n",
    "        '''\n",
    "        This function returns User Objects\n",
    "        The User object contains Twitter User account metadata \n",
    "        that describes the Twitter User referenced. Users can author \n",
    "        Tweets, Retweet, quote other Users Tweets, \n",
    "        reply to Tweets, follow Users, be @mentioned in \n",
    "        Tweets and can be grouped into lists.\n",
    "        \n",
    "        REF\n",
    "        https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/user-object\n",
    "        '''\n",
    "        users_to_get = self.get_screen_names(users,\n",
    "                                      csv=csv,\n",
    "                                      col=col, \n",
    "                                      nusers=nusers,\n",
    "                                      fname=None,\n",
    "                                      **kwargs)\n",
    "                        \n",
    "            \n",
    "        info_list = []\n",
    "        for target in users_to_get:\n",
    "            \n",
    "            item = self.get_user_data(target)\n",
    "            if item is None:\n",
    "                continue\n",
    "\n",
    "            if kwargs.get('verbose',self.verbose)>2:\n",
    "                print(\"name: \" + item['name'])\n",
    "                print(\"screen_name: \" + item['screen_name'])\n",
    "                print(\"description: \" + item['description'])\n",
    "                print(\"statuses_count: \" + str(item['statuses_count']))\n",
    "                print(\"friends_count: \" + str(item['friends_count']))\n",
    "                print(\"followers_count: \" + str(item['followers_count']))\n",
    "                print(\"account created date: \",item['created_at'])\n",
    "                print(\"Account age (in days): \" + str(item['account_age_days']))\n",
    "                if item['average_tweet_per_day'] > 0:\n",
    "                      print(\"Average tweets per day: \" + \"%.2f\"%(item['average_tweet_per_day'])) \n",
    "                                    \n",
    "\n",
    "            info_list.append(item)\n",
    "            \n",
    "        df = pd.DataFrame(info_list)\n",
    "        \n",
    "        #save\n",
    "        if not fname is None:\n",
    "            df.to_csv(fname)\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def print_most_common(self,t):\n",
    "        mentions = t['mentions']\n",
    "        hashtags = t['hashtags']\n",
    "        tweet_count = t['tweet_count']\n",
    "        \n",
    "        \n",
    "        print()\n",
    "        print(\"Most mentioned Twitter users:\")\n",
    "        for item, count in Counter(mentions).most_common(10):\n",
    "          print(item + \"\\t\" + str(count))\n",
    "\n",
    "        print()\n",
    "        print(\"Most used hashtags:\")\n",
    "        for item, count in Counter(hashtags).most_common(10):\n",
    "          print(item + \"\\t\" + str(count))\n",
    "\n",
    "        print()\n",
    "        print(\"All done. Processed \" + str(tweet_count) + \" tweets.\")\n",
    "\n",
    "    \n",
    "    def status_to_entities(self,status):\n",
    "        hashtags = []\n",
    "        mentions = []\n",
    "        \n",
    "        #get some attributes in separate list\n",
    "        if hasattr(status, \"entities\"):\n",
    "            entities = status.entities\n",
    "            #\n",
    "            if \"hashtags\" in entities:\n",
    "                for ent in entities[\"hashtags\"]:\n",
    "                    if ent is not None:\n",
    "                        if \"text\" in ent:\n",
    "                            hashtag = ent[\"text\"]\n",
    "                            if hashtag is not None:\n",
    "                                hashtags.append(hashtag)\n",
    "\n",
    "\n",
    "            if \"user_mentions\" in entities:\n",
    "                for ent in entities[\"user_mentions\"]:\n",
    "                    if ent is not None:\n",
    "                        if \"screen_name\" in ent:\n",
    "                            name = ent[\"screen_name\"]\n",
    "                            if name is not None:\n",
    "                                mentions.append(name) \n",
    "                            \n",
    "        return mentions, hashtags\n",
    "    \n",
    "    def entities_dict(self,status):\n",
    "        mentions, hashtags = self.status_to_entities(status)\n",
    "        \n",
    "        #\n",
    "        entdict = {'nmention':len(mentions), 'nhashtag':len(hashtags),\n",
    "                   'mentions':'|'.join(mentions),'hashtags':'|'.join(hashtags)}\n",
    "        \n",
    "        #\n",
    "#         for item, count in Counter(mentions).most_common(10):\n",
    "#             entdict['%s_mentions'%item] = count\n",
    "            \n",
    "#         for item, count in Counter(hashtags).most_common(10):\n",
    "#             entdict['%s_count'%item] = count    \n",
    "            \n",
    "        return entdict\n",
    "    \n",
    "    \n",
    "    def get_all_tweets(self,screen_name, \n",
    "                       fname=None,\n",
    "                       ndays=10000, \n",
    "                       nitem=10000):\n",
    "        #Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "        '''\n",
    "        Entities provide metadata and additional contextual information \n",
    "        about content posted on Twitter. The entities section provides \n",
    "        arrays of common things included in Tweets: \n",
    "        hashtags, user mentions, links, stock tickers (symbols),\n",
    "        Twitter polls, and attached media. \n",
    "        \n",
    "        More Ref:\n",
    "        https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/entities-object\n",
    "        '''\n",
    "        #\n",
    "        name = screen_name.replace('@','')\n",
    "        \n",
    "        #\n",
    "        item = self.get_user_data(screen_name)\n",
    "        if item is None:\n",
    "            return []\n",
    "\n",
    "                \n",
    "        if fname is None:\n",
    "            name = screen_name.replace('@','')\n",
    "            fname = f'users_tweets/{name}_tweets.json'\n",
    "            \n",
    "        fhandle = open(fname, 'w')\n",
    "        \n",
    "        #initialize a list to hold all the tweepy Tweets\n",
    "        alltweets = []  #tweet object sotre\n",
    "        allentities = []  #entities object store\n",
    "\n",
    "        \n",
    "        #filter tweets by date\n",
    "        if ndays>0:\n",
    "            end_date = datetime.utcnow() - timedelta(days=ndays)\n",
    "        else:\n",
    "            end_date = None\n",
    "        \n",
    "        \n",
    "        #iterate on status\n",
    "        tweet_count = 0\n",
    "        pbar = tqdm(total=3200) \n",
    "        for tweet_obj in tweepy.Cursor(self.api.user_timeline, id=screen_name).items(nitem):\n",
    "            tweet_count += 1\n",
    "            \n",
    "            #get dict\n",
    "            status = tweet_obj._json\n",
    "            \n",
    "            alltweets.append(status)   \n",
    "            \n",
    "            #write to json \n",
    "            json.dump(status,fhandle)\n",
    "            fhandle.write('\\n')\n",
    "            \n",
    "            #progress bar\n",
    "            pbar.set_description(f\"{name}: {tweet_count} tweets downloaded so far\")\n",
    "            #pbar.update(10)\n",
    "                \n",
    "            #apply date filter\n",
    "            if not end_date is None:\n",
    "                if status.created_at < end_date:\n",
    "                    break  \n",
    "                    \n",
    "            \n",
    "            \n",
    "        \n",
    "        #write to json        \n",
    "        #with open(fname, 'w') as f:\n",
    "        #    json.dump(alltweets,f)\n",
    "        fhandle.close()\n",
    "        pbar.close()\n",
    "        \n",
    "        return alltweets\n",
    "\n",
    "            \n",
    "    def get_users_tweet(self, users, \n",
    "                        csv=True,\n",
    "                        col='twitter_handle',                        \n",
    "                        nusers=0, \n",
    "                        overwrite=False,\n",
    "                        call_api=False,\n",
    "                        **kwargs):\n",
    "        #\n",
    "        #\n",
    "        users_to_get = self.get_screen_names(users,\n",
    "                                      csv=csv,\n",
    "                                      col=col, \n",
    "                                      nusers=nusers)\n",
    "        \n",
    "        alluserstweets = []\n",
    "        #\n",
    "        for screen_name in users_to_get:\n",
    "            name = screen_name.replace('@','')\n",
    "            fname = f'users_tweets/{name}_tweets.json'\n",
    "            #print(fname, 'file exists: ',os.path.exists(fname))\n",
    "            \n",
    "            #\n",
    "            if os.path.exists(fname) and not overwrite:\n",
    "                #\n",
    "                alltweets = read_tweet_json(fname) #json.load(open(fname,'r'))\n",
    "                if len(alltweets)==0:\n",
    "                    print(f\"No lines found in file {fname}\")\n",
    "                    continue\n",
    "                \n",
    "            else:\n",
    "                if call_api:\n",
    "                    try:\n",
    "                        alltweets = self.get_all_tweets(screen_name,**kwargs)\n",
    "                    except tweepy.TweepError as e:\n",
    "                        print(f\"Skipping {screen_name} .. error: {e.args[0][0]['message']}\") \n",
    "                        continue\n",
    "                else:\n",
    "                    print(f\"Skipping {screen_name} .. no local data found and call_api=False\")\n",
    "                    continue\n",
    "\n",
    "                \n",
    "            if len(alltweets)==0:\n",
    "                continue\n",
    "            else:\n",
    "                #transform the tweepy tweets into a 2D array that will populate DataFrame \n",
    "                outtweets = [{'id':tweet[\"id_str\"], \n",
    "                              'created_at':tweet[\"created_at\"], \n",
    "                              'retweet_count':tweet[\"retweet_count\"],\n",
    "                              'favorite_count':tweet[\"favorite_count\"],\n",
    "                              'is_retweet': 'retweeted_status' in tweet.keys(),\n",
    "                              'is_quoted': tweet[\"is_quote_status\"],\n",
    "                              'reply_to_status': tweet[\"in_reply_to_status_id_str\"],\n",
    "                              'reply_to_user':tweet[\"in_reply_to_user_id_str\"],\n",
    "                              'reply_to_username':tweet[\"in_reply_to_screen_name\"],\n",
    "                              'coord':tweet[\"coordinates\"],\n",
    "                              'source':tweet[\"source\"],\n",
    "                              'truncated': tweet[\"truncated\"],                              \n",
    "                              'text':tweet[\"text\"], \n",
    "                              **self.entities_dict(tweet)} for tweet in alltweets]\n",
    "\n",
    "                alluserstweets.append(pd.DataFrame(outtweets))\n",
    "            \n",
    "        return alluserstweets\n",
    "            \n",
    "            \n",
    "    def status_sentiment_info(self,status, df=None):\n",
    "\n",
    "        #if this tweet is a retweet update retweet count\n",
    "        if not df is None:\n",
    "            if status['created_at'] in df['created_at'].values:\n",
    "                i = df.loc[df['created_at'] == status['created_at']].index[0]\n",
    "                #\n",
    "                cond1 = status['favorite_count'] != df.at[i, 'favorite_count']\n",
    "                cond2 = status['retweet_count'] != df.at[i, 'retweet_count']\n",
    "                if cond1 or cond2:\n",
    "                    df.at[i, 'favorite_count'] = status['favorite_count']\n",
    "                    df.at[i, 'retweet_count'] = status['retweet_count']\n",
    "                    \n",
    "            return []\n",
    "\n",
    "        #calculate sentiment\n",
    "        filtered_tweet = self.clean_tweets(status['full_text'])\n",
    "        blob = TextBlob(filtered_tweet)\n",
    "        Sentiment = blob.sentiment     \n",
    "        polarity = Sentiment.polarity\n",
    "        subjectivity = Sentiment.subjectivity\n",
    "\n",
    "        \n",
    "        new_entry = [status['id'], status['created_at'],\n",
    "                      status['source'], status['full_text'], filtered_tweet, \n",
    "                      Sentiment,polarity,subjectivity, status['lang'],\n",
    "                      status['favorite_count'], status['retweet_count']]\n",
    "\n",
    "        new_entry.append(status['user']['screen_name'])\n",
    "\n",
    "        try:\n",
    "            is_sensitive = status['possibly_sensitive']\n",
    "        except KeyError:\n",
    "            is_sensitive = None\n",
    "\n",
    "        new_entry.append(is_sensitive)\n",
    "\n",
    "        hashtags = \", \".join([hashtag_item['text'] for hashtag_item in \\\n",
    "                              status['entities']['hashtags']])\n",
    "        new_entry.append(hashtags) #append the hashtags\n",
    "\n",
    "        #\n",
    "        mentions = \", \".join([mention['screen_name'] for mention in \\\n",
    "                              status['entities']['user_mentions']])\n",
    "        new_entry.append(mentions) #append the user mentions\n",
    "\n",
    "        try:\n",
    "            xyz = status['place']['bounding_box']['coordinates']\n",
    "            coordinates = [coord for loc in xyz for coord in loc]\n",
    "        except TypeError:\n",
    "            coordinates = None\n",
    "        #\n",
    "        new_entry.append(coordinates)\n",
    "\n",
    "        try:\n",
    "            location = status['user']['location']\n",
    "        except TypeError:\n",
    "            location = ''\n",
    "        #\n",
    "        new_entry.append(location)  \n",
    "        \n",
    "        return new_entry\n",
    "            \n",
    "    def get_tweets(self, keyword, fname, csvfile=None, \n",
    "                   append=True, npages=100,ncount=1000,\n",
    "                   nmax=0, overwrite=False):\n",
    "        \n",
    "        \n",
    "        df = pd.DataFrame(columns=self.cols)\n",
    "        \n",
    "        #read csv and return if append is False\n",
    "        if not csvfile is None:\n",
    "            #If the file exists, then read the existing data from the CSV file.\n",
    "            if os.path.exists(csvfile):\n",
    "                df = pd.read_csv(csvfile, header=0)\n",
    "            \n",
    "        fhandle = None\n",
    "        \n",
    "        #progress bar initiate\n",
    "        icount = 0\n",
    "        ipage = 0\n",
    "        \n",
    "        #\n",
    "        pbar = tqdm(total=ncount*int(max([40,ncount])) )\n",
    "        print(f'search & download with keyword: {keyword}')\n",
    "        \n",
    "        alltweets = []\n",
    "        \n",
    "        #check if json file exists\n",
    "        if os.path.exists(fname) and not (overwrite or append):\n",
    "            print(f'Reading existing {fname} file')\n",
    "            \n",
    "            alltweets = read_tweet_json(fname, func=self.status_sentiment_info, nmax=nmax)    \n",
    "\n",
    "        else:      \n",
    "            #call api, get data, save tweets to json\n",
    "            \n",
    "            print('Calling tweepy.Cursor with self.api.search_tweets .. ')\n",
    "            \n",
    "            if append and os.path.exists(fname):\n",
    "                fhandle = open(fname, 'a')\n",
    "            else:             \n",
    "                fhandle = open(fname, 'w')                \n",
    "            \n",
    "            \n",
    "            #page attribute in tweepy.cursor and iteration\n",
    "            for page in tweepy.Cursor(self.api.search_tweets, q=keyword,count=ncount, \n",
    "                                      include_rts=False,tweet_mode='extended').pages(npages):\n",
    "\n",
    "                # the you receive from the Twitter API is in a JSON format and has quite an \n",
    "                # amount of information attached\n",
    "                print('page item: len(page)=',len(page))\n",
    "                \n",
    "                for status in page:\n",
    "\n",
    "\n",
    "                    status = status._json\n",
    "\n",
    "                    #write to json \n",
    "                    json.dump(status,fhandle)\n",
    "                    fhandle.write('\\n')\n",
    "\n",
    "                    #filter by language\n",
    "                    #if status['lang'] != 'en':\n",
    "                    #    continue\n",
    "\n",
    "                    new_entry = self.status_sentiment_info(status,df=df)\n",
    "                    if len(new_entry)>0:\n",
    "                        alltweets.append(new_entry)\n",
    "\n",
    "                    #info                \n",
    "                    #pbar.set_description(f\"tweets downloaded so far: {icount}\")\n",
    "                    #pbar.update(1)\n",
    "                    icount += 1\n",
    "\n",
    "                ipage += 1\n",
    "                print(f'page={ipage}, #tweet={icount}')\n",
    "            \n",
    "\n",
    "        #close open states\n",
    "        print(f'keyword: {keyword}')\n",
    "        print(f\"total #tweets downloaded: {len(alltweets)}\")\n",
    "        pbar.close()\n",
    "        \n",
    "        #close file if open\n",
    "        if not fhandle is None:\n",
    "            fhandle.close()\n",
    "        \n",
    "        \n",
    "        #now append a row to the dataframe\n",
    "        df_new = pd.DataFrame(alltweets, columns=self.cols)\n",
    "        try:\n",
    "            df = pd.concat([df_new, df]).drop_duplicates()\n",
    "        except:\n",
    "            df = df_new\n",
    "        \n",
    "    \n",
    "        #\n",
    "        df['timestamp'] = df.created_at.map(pd.Timestamp)\n",
    "        df = df.sort_values('timestamp').set_index('timestamp')\n",
    "        df = df.drop('id',axis=1)\n",
    "        \n",
    "        if not csvfile is None:\n",
    "            #save it to file\n",
    "            try:\n",
    "                df.to_csv(csvfile, columns=self.cols, index=True, encoding=\"utf-8\")\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = 'Alemnew'\n",
    "# title = 'Mr'\n",
    "# print('Method 1: My name is %s %s'%(title, name))\n",
    "# print('Method 2: My name is {0} {1}'.format(title, name))\n",
    "# print('Method 2.1: My name is {title} {name}'.format(**{'title':title, 'name':name}))\n",
    "# print('Method 2.2: My name is {title} {name}'.format(title=title, name=name))\n",
    "# print(f'Method 3: My name is {title} {name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search tweets of users by screen name\n",
    "Here we are going to get the twitter information of users. Initialise class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ts = tweetsearch()\n",
    "#ts.limit_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                   | 0/1000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search & download with keyword: ['ethiopia']\n",
      "Reading existing data/ethiopia_nomore.csv file\n",
      "trying method 1\n",
      "failed to process line=15547\n",
      "failed to process line=16497\n",
      "failed to process line=16780\n",
      "failed to process line=16781\n",
      "failed to process line=71106\n",
      "failed to process line=84818\n",
      "failed to process line=84819\n",
      "failed to process line=111397\n",
      "failed to process line=127994\n",
      "failed to process line=147589\n",
      "failed to process line=152657\n",
      "failed to process line=152659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                   | 0/1000000 [02:37<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#tweets from data/ethiopia_nomore.csv: 156448\n",
      "number of lines failed to read: 12\n",
      "keyword: ['ethiopia']\n",
      "total #tweets downloaded: 156448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ts = tweetsearch()\n",
    "\n",
    "fname = 'data/ethiopia_nomore.csv'\n",
    "\n",
    "overwrite = False\n",
    "append = False\n",
    "\n",
    "#keyword = ['NOMORE','nomore','no_more','NoMore']\n",
    "keyword = ['ethiopia']\n",
    "dfig = ts.get_tweets(keyword, fname,overwrite=overwrite, append=append, nmax=0,  ncount=1000, npages=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 156448 entries, 2021-12-25 09:51:10+00:00 to 2021-12-27 21:54:58+00:00\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   created_at              156448 non-null  object \n",
      " 1   source                  156448 non-null  object \n",
      " 2   original_text           156448 non-null  object \n",
      " 3   clean_text              156448 non-null  object \n",
      " 4   sentiment               156448 non-null  object \n",
      " 5   polarity                156448 non-null  float64\n",
      " 6   subjectivity            156448 non-null  float64\n",
      " 7   lang                    156448 non-null  object \n",
      " 8   favorite_count          156448 non-null  int64  \n",
      " 9   retweet_count           156448 non-null  int64  \n",
      " 10  original_author         156448 non-null  object \n",
      " 11  possibly_sensitive      25352 non-null   object \n",
      " 12  hashtags                156448 non-null  object \n",
      " 13  user_mentions           156448 non-null  object \n",
      " 14  place                   184 non-null     object \n",
      " 15  place_coord_boundaries  156448 non-null  object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 20.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dfig.info() #[(df.location=='Ethiopia') & (df_users.excess_followers>200)]\n",
    "#dff #.head()\n",
    "#dff.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtags(post):\n",
    "    tag = {}\n",
    "    for sentence in post:\n",
    "        words = sentence.split(\",\")\n",
    "        for w in words:\n",
    "            if len(w) > 0:\n",
    "                word = w.strip()\n",
    "                if word in tag.keys():\n",
    "                    tag[word] +=1\n",
    "                else:\n",
    "                    tag[word] = 1\n",
    "    return tag            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = dfig[\"hashtags\"]\n",
    "dichash = hashtags(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhash = pd.Series(dichash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhash = dfhash.sort_values(ascending = False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethiopia                      45875\n",
      "Tigray                        27025\n",
      "NoMore                        14053\n",
      "TigrayGenocide                 9558\n",
      "KnowMore                       6153\n",
      "Eritrea                        5089\n",
      "Africa                         4778\n",
      "StopDroneAttacks               4173\n",
      "US                             3203\n",
      "TigrayIsAfrica                 2953\n",
      "Tigraygenocide                 2935\n",
      "Turkey                         2898\n",
      "UnityForEthiopia               2548\n",
      "Biden                          2471\n",
      "Blinken                        2402\n",
      "AGOA                           2382\n",
      "Tigrayans                      2192\n",
      "StopWarOnTigray                2191\n",
      "TerroristTPLF                  2031\n",
      "TPLF                           1849\n",
      "NoFlyZoneInTigray              1787\n",
      "EtiyopyayıSilahlandırmayın     1751\n",
      "IC                             1651\n",
      "China                          1609\n",
      "UN                             1595\n",
      "TPLFTerroristGroup             1592\n",
      "UAE                            1540\n",
      "Amhara                         1442\n",
      "Ethiopians                     1246\n",
      "LestWeForget                   1203\n",
      "Afar                           1005\n",
      "GreatEthiopianHomeComing        967\n",
      "Alamata                         958\n",
      "AbiyAhmed                       869\n",
      "Iran                            783\n",
      "Oromia                          703\n",
      "TigrayMassArrests               692\n",
      "Türk                            666\n",
      "TigrayFamine                    631\n",
      "tigray                          600\n",
      "EndTigraySiege                  599\n",
      "StopArmingEthiopia              586\n",
      "StopBombingTigray               574\n",
      "TwitterRacism                   554\n",
      "NeverAgain4Tigray               535\n",
      "Mekelle                         526\n",
      "USA                             514\n",
      "CNN                             509\n",
      "Syria                           507\n",
      "Maychew                         505\n",
      "EthiopiaPrevails                494\n",
      "Muslim                          492\n",
      "Somalia                         487\n",
      "EU                              481\n",
      "TDF                             467\n",
      "Korem                           465\n",
      "Chena                           461\n",
      "Maikadra                        458\n",
      "TPLFSURRENDERNOW                458\n",
      "Glecoma                         455\n",
      "dtype: int64 StopTigrayGenocide          455\n",
      "Ethiopian                   443\n",
      "Justice4Tigray              399\n",
      "HOA                         393\n",
      "Sudan                       375\n",
      "CallItAGenocide             371\n",
      "HateSpeech                  353\n",
      "HealAndRestore              351\n",
      "ethiopia                    340\n",
      "COIforTigray                325\n",
      "1YearOfTigrayGenocide       323\n",
      "war                         316\n",
      "GreatEthiopianHomecoming    309\n",
      "Tigrayan                    305\n",
      "peace                       305\n",
      "nomore                      278\n",
      "Etiyopya                    253\n",
      "Afghanistan                 246\n",
      "AmharaGenocide              243\n",
      "WesternTigray               239\n",
      "AbiyAhmedAli                236\n",
      "GreatHomecoming             234\n",
      "SaveTigrayans               228\n",
      "STOP                        228\n",
      "AfarGenocide                219\n",
      "NoParallelMarket            219\n",
      "TurkeyDroneSale             219\n",
      "Yemen                       211\n",
      "Adwa                        210\n",
      "WarOnTigray                 205\n",
      "tigrayfamine                198\n",
      "Lehager                     196\n",
      "genocide                    196\n",
      "kenya                       190\n",
      "africa                      189\n",
      "FakeCNN                     189\n",
      "NeverAgain                  188\n",
      "sudan                       188\n",
      "rwanda                      187\n",
      "eritrea                     186\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dfhash.head(60),dfhash.tail(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "plthash = dfhash.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "plthash=plthash.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ploting top 5 hashtag\n",
    "ind = np.arange(len(plthash))\n",
    "fig,ax = plt.subplots(figsize =(15,7))\n",
    "ax.set_title(\"Top 10 Hashtags \", fontsize = 20)\n",
    "plt.bar(ind, list(plthash.values()))\n",
    "plt.xticks(ind, list(plthash.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "vistweet.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:twitter]",
   "language": "python",
   "name": "conda-env-twitter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
